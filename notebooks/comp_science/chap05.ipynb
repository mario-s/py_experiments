{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic algorithms\n",
    "They are called upon when traditional algorithmic approaches are insufficient for arriving at a solution to a problem in a reasonable amount of time. In other words, genetic algorithms are usually reserved for complex problems without easy solutions. \n",
    "\n",
    "A genetic algorithm includes a population (group) of individuals known as chromosomes. The chromosomes, each composed of genes that specify their traits, are competing to solve some problem. How well a chromosome solves a problem is defined by a fitness function.\n",
    "\n",
    "The genetic algorithm goes through generations. In each generation, the chromosomes that are more fit are more likely to be selected to reproduce. There is also a probability in each generation that two chromosomes will have their genes merged. This is known as crossover. And finally, there is the important possibility in each generation that a gene in a chromosome may mutate (randomly change).\n",
    "\n",
    "After the fitness function of some individual in the population crosses some specified threshold, or the algorithm runs through some specified maximum number of generations, the best individual (the one that scored highest in the fitness function) is returned.\n",
    "\n",
    "Genetic algorithms are not a good solution for all problems. They depend on three partially or fully stochastic (randomly determined) operations: selection, crossover, and mutation. Therefore, they may not find an optimal solution in a reasonable amount of time. For most problems, more deterministic algorithms exist with better guarantees. But there are problems for which no fast deterministic algorithm exists. In these cases, genetic algorithms are a good choice. \n",
    "\n",
    "We will start by defining an interface for the individuals that the generic algorithm can operate on. The abstract class Chromosome defines four essential features. A chromosome must be able to do the following:\n",
    "\n",
    "- Determine its own fitness\n",
    "- Create an instance with randomly selected genes (for use in filling the first generation)\n",
    "- Implement crossover (combine itself with another of the same type to create children)—in other words, mix itself with another chromosome\n",
    "- Mutate—make a small, fairly random change in itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import TypeVar, Tuple, Type\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "T = TypeVar('T', bound='Chromosome') # for returning self\n",
    "\n",
    "# Base class for all chromosomes; all methods must be overridden\n",
    "class Chromosome(ABC):\n",
    "    @abstractmethod\n",
    "    def fitness(self) -> float:\n",
    "        ...\n",
    "\n",
    "    @classmethod\n",
    "    @abstractmethod\n",
    "    def random_instance(cls: Type[T]) -> T:\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def crossover(self: T, other: T) -> Tuple[T, T]:\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def mutate(self) -> None:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implement the algorithm itself (the code that will manipulate chromosomes) as a generic class that is open to subclassing for future specialized applications.\n",
    "\n",
    "GeneticAlgorithm takes a generic type that conforms to Chromosome, and its name is C. The enum SelectionType is an internal type used for specifying the selection method used by the algorithm. The two most common genetic algorithm selection methods are known as roulette-wheel selection (sometimes called fitness proportionate selection) and tournament selection. The former gives every chromosome a chance of being picked, proportionate to its fitness. In tournament selection, a certain number of random chromosomes are challenged against one another, and the one with the best fitness is selected. \n",
    "\n",
    "In the __init__ method the initial_population is the chromosomes in the first generation of the algorithm. threshold is the fitness level that indicates that a solution has been found for the problem that the genetic algorithm is trying to solve. max_generations is the maximum number of generations to run. If we have run that many generations and no solution with a fitness level beyond threshold has been found, the best solution that has been found will be returned. mutation_chance is the probability of each chromosome in each generation mutating. crossover_chance is the probability that two parents selected to reproduce have children that are a mixture of their genes; otherwise, the children are just duplicates of the parents. Finally, selection_type is the type of selection method to use, as delineated by the enum SelectionType. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypeVar, Generic, List, Tuple, Callable\n",
    "from enum import Enum\n",
    "from random import choices, random\n",
    "from heapq import nlargest\n",
    "from statistics import mean\n",
    "\n",
    "C = TypeVar('C', bound=Chromosome) # type of the chromosomes\n",
    "\n",
    "class GeneticAlgorithm(Generic[C]):\n",
    "    SelectionType = Enum(\"SelectionType\", \"ROULETTE TOURNAMENT\")\n",
    "    \n",
    "    def __init__(self, initial_population: List[C], threshold: float, max_generations: int = 100, \n",
    "                 mutation_chance: float = 0.01, crossover_chance: float = 0.7, \n",
    "                 selection_type: SelectionType = SelectionType.TOURNAMENT) -> None:\n",
    "        self._population: List[C] = initial_population\n",
    "        self._threshold: float = threshold\n",
    "        self._max_generations: int = max_generations\n",
    "        self._mutation_chance: float = mutation_chance\n",
    "        self._crossover_chance: float = crossover_chance\n",
    "        self._selection_type: GeneticAlgorithm.SelectionType = selection_type\n",
    "        self._fitness_key: Callable = type(self._population[0]).fitness\n",
    "    \n",
    "    \n",
    "    # Use the probability distribution wheel to pick 2 parents\n",
    "    # Note: will not work with negative fitness results\n",
    "    def _pick_roulette(self, wheel: List[float]) -> Tuple[C, C]:\n",
    "        return tuple(choices(self._population, weights=wheel, k=2))\n",
    "    \n",
    "    \n",
    "    # randomly pick num_participants from _population. Then use\n",
    "    # the nlargest() function from the heapq module to find \n",
    "    # the two largest individuals by _fitness_key\n",
    "    def _pick_tournament(self, num_participants: int) -> Tuple[C, C]:\n",
    "        participants: List[C] = choices(self._population, k=num_participants)\n",
    "        return tuple(nlargest(2, participants, key=self._fitness_key))\n",
    "    \n",
    "    \n",
    "    # Replace the population with a new generation of individuals\n",
    "    def _reproduce_and_replace(self) -> None:\n",
    "        new_population: List[C] = []\n",
    "        # keep going until we've filled the new generation\n",
    "        while len(new_population) < len(self._population):\n",
    "            # pick the 2 parents\n",
    "            if self._selection_type == GeneticAlgorithm.SelectionType.ROULETTE:\n",
    "                parents: Tuple[C, C] = self._pick_roulette([x.fitness() for x in self._population])\n",
    "            else:\n",
    "                parents = self._pick_tournament(len(self._population) // 2)\n",
    "                \n",
    "            # potentially crossover the 2 parents\n",
    "            if random() < self._crossover_chance:\n",
    "                new_population.extend(parents[0].crossover(parents[1]))\n",
    "            else:\n",
    "                new_population.extend(parents)\n",
    "                \n",
    "        # if we had an odd number, we'll have 1 extra, so we remove it\n",
    "        if len(new_population) > len(self._population):\n",
    "            new_population.pop()\n",
    "        self._population = new_population # replace reference\n",
    "        \n",
    "        \n",
    "    # With _mutation_chance probability mutate each individual\n",
    "    def _mutate(self) -> None:\n",
    "        for individual in self._population:\n",
    "            if random() < self._mutation_chance:\n",
    "                individual.mutate()\n",
    "                \n",
    "                \n",
    "    # Run the genetic algorithm for max_generations iterations\n",
    "    # and return the best individual found\n",
    "    def run(self) -> C:\n",
    "        best: C = max(self._population, key=self._fitness_key)\n",
    "        for generation in range(self._max_generations):\n",
    "            # early exit if we beat threshold\n",
    "            if best.fitness() >= self._threshold: \n",
    "                return best\n",
    "            \n",
    "            print(f\"Generation {generation} Best {best.fitness()} Avg {mean(map(self._fitness_key, self._population))}\")\n",
    "            self._reproduce_and_replace()\n",
    "            self._mutate()\n",
    "            highest: C = max(self._population, key=self._fitness_key)\n",
    "            if highest.fitness() > best.fitness():\n",
    "                best = highest # found a new best\n",
    "        return best # best we found in _max_generations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Test\n",
    "As a test, we will start by implementing a simple problem that can be easily solved using traditional methods. We will try to maximize the equation 6x – x2 + 4y – y2. In other words, what values for x and y in that equation will yield the largest number?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange, random\n",
    "from copy import deepcopy\n",
    "\n",
    "class SimpleEquation(Chromosome):\n",
    "    def __init__(self, x: int, y: int) -> None:\n",
    "        self.x: int = x\n",
    "        self.y: int = y\n",
    "\n",
    "    def fitness(self) -> float: # 6x - x^2 + 4y - y^2\n",
    "        return 6 * self.x - self.x * self.x + 4 * self.y - self.y * self.y\n",
    "    @classmethod\n",
    "    def random_instance(cls) -> SimpleEquation:\n",
    "        return SimpleEquation(randrange(100), randrange(100))\n",
    "\n",
    "    def crossover(self, other: SimpleEquation) -> Tuple[SimpleEquation,\n",
    "     SimpleEquation]:\n",
    "        child1: SimpleEquation = deepcopy(self)\n",
    "        child2: SimpleEquation = deepcopy(other)\n",
    "        child1.y = other.y\n",
    "        child2.y = self.y\n",
    "        return child1, child2\n",
    "\n",
    "    def mutate(self) -> None:\n",
    "        if random() > 0.5: # mutate x\n",
    "            if random() > 0.5:\n",
    "                self.x += 1\n",
    "            else:\n",
    "                self.x -= 1\n",
    "        else: # otherwise mutate y\n",
    "            if random() > 0.5:\n",
    "                self.y += 1\n",
    "            else:\n",
    "                self.y -= 1\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"X: {self.x} Y: {self.y} Fitness: {self.fitness()}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method fitness() evaluates x and y using the equation 6x – x2 + 4y – y2. The higher the value, the more fit the individual chromosome is, according to Genetic-Algorithm. In the case of a random instance, x and y are initially set to be random integers between 0 and 100, so random_instance() does not need to do anything other than instantiate a new SimpleEquation with these values. To combine one Simple-Equation with another in crossover(), the y values of the two instances are simply swapped to create the two children. mutate() randomly increments or decrements x or y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0 Best -88 Avg -5078.85\n",
      "Generation 1 Best -87 Avg -1072.85\n",
      "Generation 2 Best -87 Avg -133.55\n",
      "Generation 3 Best -87 Avg -87.05\n",
      "Generation 4 Best -68 Avg -87.2\n",
      "Generation 5 Best -68 Avg -84.15\n",
      "Generation 6 Best -68 Avg -74.7\n",
      "Generation 7 Best -51 Avg -66.45\n",
      "Generation 8 Best -36 Avg -56.3\n",
      "Generation 9 Best -36 Avg -45.75\n",
      "Generation 10 Best -36 Avg -38.4\n",
      "Generation 11 Best -36 Avg -36\n",
      "Generation 12 Best -23 Avg -34.2\n",
      "Generation 13 Best -23 Avg -27.55\n",
      "Generation 14 Best -23 Avg -23.8\n",
      "Generation 15 Best -23 Avg -23\n",
      "Generation 16 Best -23 Avg -23.05\n",
      "Generation 17 Best -23 Avg -23.7\n",
      "Generation 18 Best -12 Avg -21.95\n",
      "Generation 19 Best -12 Avg -19.9\n",
      "Generation 20 Best -3 Avg -11.8\n",
      "Generation 21 Best -3 Avg -8.95\n",
      "Generation 22 Best 4 Avg -4.1\n",
      "Generation 23 Best 9 Avg -1.4\n",
      "Generation 24 Best 9 Avg 1.5\n",
      "Generation 25 Best 12 Avg 8.6\n",
      "Generation 26 Best 12 Avg 9.3\n",
      "X: 3 Y: 2 Fitness: 13\n"
     ]
    }
   ],
   "source": [
    "initial_population: List[SimpleEquation] = [SimpleEquation.random_instance() for _ in range(20)]\n",
    "ga: GeneticAlgorithm[SimpleEquation] = GeneticAlgorithm(initial_population=initial_population, \n",
    "                                                        threshold=13.0, max_generations = 100,\n",
    "                                                        mutation_chance = 0.1, crossover_chance = 0.7)\n",
    "result: SimpleEquation = ga.run()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEND+MORE=MONEY\n",
    "A chromosome that represents the SEND+MORE=MONEY problem is represented in SendMoreMoney2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle, sample\n",
    "\n",
    "class SendMoreMoney2(Chromosome):\n",
    "    def __init__(self, letters: List[str]) -> None:\n",
    "        self.letters: List[str] = letters\n",
    "\n",
    "    def fitness(self) -> float:\n",
    "        s: int = self.letters.index(\"S\")\n",
    "        e: int = self.letters.index(\"E\")\n",
    "        n: int = self.letters.index(\"N\")\n",
    "        d: int = self.letters.index(\"D\")\n",
    "        m: int = self.letters.index(\"M\")\n",
    "        o: int = self.letters.index(\"O\")\n",
    "        r: int = self.letters.index(\"R\")\n",
    "        y: int = self.letters.index(\"Y\")\n",
    "        send: int = s * 1000 + e * 100 + n * 10 + d\n",
    "        more: int = m * 1000 + o * 100 + r * 10 + e\n",
    "        money: int = m * 10000 + o * 1000 + n * 100 + e * 10 + y\n",
    "        difference: int = abs(money - (send + more))\n",
    "        #Dividing 1 by a fitness value is a simple way to convert a minimization problem into a maximization problem.\n",
    "        return 1 / (difference + 1) \n",
    "\n",
    "    @classmethod\n",
    "    def random_instance(cls) -> SendMoreMoney2:\n",
    "        letters = [\"S\", \"E\", \"N\", \"D\", \"M\", \"O\", \"R\", \"Y\", \" \", \" \"]\n",
    "        shuffle(letters)\n",
    "        return SendMoreMoney2(letters)\n",
    "\n",
    "    def crossover(self, other: SendMoreMoney2) -> Tuple[SendMoreMoney2,\n",
    "     SendMoreMoney2]:\n",
    "        child1: SendMoreMoney2 = deepcopy(self)\n",
    "        child2: SendMoreMoney2 = deepcopy(other)\n",
    "            \n",
    "        idx1, idx2 = sample(range(len(self.letters)), k=2)\n",
    "        \n",
    "        l1, l2 = child1.letters[idx1], child2.letters[idx2]\n",
    "        \n",
    "        child1.letters[child1.letters.index(l2)], child1.letters[idx2] = child1.letters[idx2], l2\n",
    "        child2.letters[child2.letters.index(l1)], child2.letters[idx1] = child2.letters[idx1], l1\n",
    "        \n",
    "        return child1, child2\n",
    "\n",
    "    def mutate(self) -> None: # swap two letters' locations\n",
    "        idx1, idx2 = sample(range(len(self.letters)), k=2)\n",
    "        self.letters[idx1], self.letters[idx2] = self.letters[idx2], self.letters[idx1]\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        s: int = self.letters.index(\"S\")\n",
    "        e: int = self.letters.index(\"E\")\n",
    "        n: int = self.letters.index(\"N\")\n",
    "        d: int = self.letters.index(\"D\")\n",
    "        m: int = self.letters.index(\"M\")\n",
    "        o: int = self.letters.index(\"O\")\n",
    "        r: int = self.letters.index(\"R\")\n",
    "        y: int = self.letters.index(\"Y\")\n",
    "        send: int = s * 1000 + e * 100 + n * 10 + d\n",
    "        more: int = m * 1000 + o * 100 + r * 10 + e\n",
    "        money: int = m * 10000 + o * 1000 + n * 100 + e * 10 + y\n",
    "        difference: int = abs(money - (send + more))\n",
    "        return f\"{send} + {more} = {money} Difference: {difference}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plug SendMoreMoney2 into GeneticAlgorithm just as easily as we plugged in SimpleEquation. This is a fairly tough problem, and it will take a long time to execute if the parameters are not well tweaked. And there’s still some randomness even if one gets them right! The problem may be solved in a few seconds or a few minutes. Unfortunately, that is the nature of genetic algorithms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0 Best 0.025 Avg 0.0001457122557245635\n",
      "Generation 1 Best 0.5 Avg 0.005598252928113855\n",
      "Generation 2 Best 0.5 Avg 0.12251012982351211\n",
      "3829 + 458 = 4287 Difference: 0\n"
     ]
    }
   ],
   "source": [
    "initial_population: List[SendMoreMoney2] = [SendMoreMoney2.random_instance() for _ in range(1000)]\n",
    "ga: GeneticAlgorithm[SendMoreMoney2] = GeneticAlgorithm(initial_population=initial_population, \n",
    "                                                        threshold=1.0, max_generations = 1000,\n",
    "                                                        mutation_chance = 0.2, crossover_chance = 0.7, \n",
    "                                                        selection_type=GeneticAlgorithm.SelectionType.ROULETTE)\n",
    "result: SendMoreMoney2 = ga.run()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This solution indicates that SEND = 8324, MORE = 913, and MONEY = 9237. How is that possible? It looks like letters are missing from the solution. In fact, if M = 0, there are several solutions to the problem not possible in the version from chapter 3. MORE is actually 0913 here, and MONEY is 09237. The 0 is just ignored. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Compression\n",
    "Suppose that we have some information we want to compress. Suppose that it is a list of items, and we do not care about the order of the items, as long as all of them are intact. What order of the items will maximize the compression ratio? Did you even know that the order of the items will affect the compression ratio for most compression algorithms?\n",
    "\n",
    "The answer will depend on the compression algorithm used. For this example, we will use the compress() function from the zlib module with its standard settings. The solution is shown here in its entirety for a list of 12 first names. If we do not run the genetic algorithm and we just run compress() on the 12 names in the order they were originally presented, the resulting compressed data will be 165 bytes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zlib import compress\n",
    "from sys import getsizeof\n",
    "from pickle import dumps\n",
    "\n",
    "# 165 bytes compressed\n",
    "PEOPLE: List[str] = [\"Michael\", \"Sarah\", \"Joshua\", \"Narine\", \"David\",\n",
    "     \"Sajid\", \"Melanie\", \"Daniel\", \"Wei\", \"Dean\", \"Brian\", \"Murat\", \"Lisa\"] \n",
    "\n",
    "\n",
    "class ListCompression(Chromosome):\n",
    "    def __init__(self, lst: List[Any]) -> None:\n",
    "        self.lst: List[Any] = lst\n",
    "\n",
    "    @property\n",
    "    def bytes_compressed(self) -> int:\n",
    "        return getsizeof(compress(dumps(self.lst)))\n",
    "\n",
    "    def fitness(self) -> float:\n",
    "        return 1 / self.bytes_compressed\n",
    "\n",
    "    @classmethod\n",
    "    def random_instance(cls) -> ListCompression:\n",
    "        mylst: List[str] = deepcopy(PEOPLE)\n",
    "        shuffle(mylst)\n",
    "        return ListCompression(mylst)\n",
    "\n",
    "    def crossover(self, other: ListCompression) -> Tuple[ListCompression,\n",
    "     ListCompression]:\n",
    "        child1: ListCompression = deepcopy(self)\n",
    "        child2: ListCompression = deepcopy(other)\n",
    "            \n",
    "        idx1, idx2 = sample(range(len(self.lst)), k=2)\n",
    "        \n",
    "        l1, l2 = child1.lst[idx1], child2.lst[idx2]\n",
    "        \n",
    "        child1.lst[child1.lst.index(l2)], child1.lst[idx2] = child1.lst[idx2], l2\n",
    "        child2.lst[child2.lst.index(l1)], child2.lst[idx1] = child2.lst[idx1], l1\n",
    "        \n",
    "        return child1, child2\n",
    "\n",
    "    def mutate(self) -> None: # swap two locations\n",
    "        idx1, idx2 = sample(range(len(self.lst)), k=2)\n",
    "        self.lst[idx1], self.lst[idx2] = self.lst[idx2], self.lst[idx1]\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"Order: {self.lst} Bytes: {self.bytes_compressed}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how similar this implementation is to the implementation from SEND+MORE=MONEY. The crossover() and mutate() functions are essentially the same. In both problems’ solutions, we are taking a list of items and continually rearranging them and testing those rearrangements. One could write a generic superclass for both problems’ solutions that would work with a wide variety of problems. Any problem that can be represented as a list of items that needs to find its optimal order could be solved the same way. The only real point of customization for the subclasses would be their respective fitness functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0 Best 0.006172839506172839 Avg 0.006049952017048166\n",
      "Generation 1 Best 0.006211180124223602 Avg 0.006090818191233948\n",
      "Generation 2 Best 0.006211180124223602 Avg 0.006123881628496068\n",
      "Generation 3 Best 0.006211180124223602 Avg 0.006162512200749813\n",
      "Generation 4 Best 0.006211180124223602 Avg 0.00616795604188583\n",
      "Generation 5 Best 0.006211180124223602 Avg 0.006166685047684451\n",
      "Generation 6 Best 0.006211180124223602 Avg 0.0061719440336855105\n",
      "Generation 7 Best 0.006211180124223602 Avg 0.006171864111434478\n",
      "Generation 8 Best 0.006211180124223602 Avg 0.006178250554047254\n",
      "Generation 9 Best 0.006211180124223602 Avg 0.006185951075260012\n",
      "Generation 10 Best 0.006211180124223602 Avg 0.0061900232746894554\n",
      "Generation 11 Best 0.006211180124223602 Avg 0.00619053424942791\n",
      "Generation 12 Best 0.006211180124223602 Avg 0.006193754406476318\n",
      "Generation 13 Best 0.006211180124223602 Avg 0.00619385100908944\n",
      "Generation 14 Best 0.006211180124223602 Avg 0.006193780787379312\n",
      "Generation 15 Best 0.006211180124223602 Avg 0.006193711118438037\n",
      "Generation 16 Best 0.006211180124223602 Avg 0.00619321826783384\n",
      "Generation 17 Best 0.006211180124223602 Avg 0.006195254771448531\n",
      "Generation 18 Best 0.006211180124223602 Avg 0.006194731483626847\n",
      "Generation 19 Best 0.006211180124223602 Avg 0.006192917975561926\n",
      "Generation 20 Best 0.006211180124223602 Avg 0.006196260258942122\n",
      "Generation 21 Best 0.006211180124223602 Avg 0.006192321777158177\n",
      "Generation 22 Best 0.006211180124223602 Avg 0.0061942984034242385\n",
      "Generation 23 Best 0.006211180124223602 Avg 0.006195669428312496\n",
      "Generation 24 Best 0.006211180124223602 Avg 0.006193306899768486\n",
      "Generation 25 Best 0.006211180124223602 Avg 0.006195613164813309\n",
      "Generation 26 Best 0.006211180124223602 Avg 0.0061958256556001855\n",
      "Generation 27 Best 0.006211180124223602 Avg 0.006193219679144934\n",
      "Generation 28 Best 0.006211180124223602 Avg 0.006193561417845524\n",
      "Generation 29 Best 0.006211180124223602 Avg 0.006193608543321225\n",
      "Generation 30 Best 0.006211180124223602 Avg 0.0061953027017783635\n",
      "Generation 31 Best 0.006211180124223602 Avg 0.006192916590478454\n",
      "Generation 32 Best 0.006211180124223602 Avg 0.006195461725460619\n",
      "Generation 33 Best 0.006211180124223602 Avg 0.006195410326128018\n",
      "Generation 34 Best 0.006211180124223602 Avg 0.006195226448982046\n",
      "Generation 35 Best 0.006211180124223602 Avg 0.006192947993356139\n",
      "Generation 36 Best 0.006211180124223602 Avg 0.006193102262697422\n",
      "Generation 37 Best 0.006211180124223602 Avg 0.006191583724315271\n",
      "Generation 38 Best 0.006211180124223602 Avg 0.00619395358368659\n",
      "Generation 39 Best 0.006211180124223602 Avg 0.006196253852073729\n",
      "Generation 40 Best 0.006211180124223602 Avg 0.006194996515072334\n",
      "Generation 41 Best 0.006211180124223602 Avg 0.00619344365879888\n",
      "Generation 42 Best 0.006211180124223602 Avg 0.006194157264014054\n",
      "Generation 43 Best 0.006211180124223602 Avg 0.006193706886148577\n",
      "Generation 44 Best 0.006211180124223602 Avg 0.006195073726775736\n",
      "Generation 45 Best 0.006211180124223602 Avg 0.006193451049765166\n",
      "Generation 46 Best 0.006211180124223602 Avg 0.006192690805280948\n",
      "Generation 47 Best 0.006211180124223602 Avg 0.006196266130747303\n",
      "Generation 48 Best 0.006211180124223602 Avg 0.0061939346958735375\n",
      "Generation 49 Best 0.006211180124223602 Avg 0.006195680968591711\n",
      "Generation 50 Best 0.006211180124223602 Avg 0.0061965798268112\n",
      "Generation 51 Best 0.006211180124223602 Avg 0.006194237751148325\n",
      "Generation 52 Best 0.006211180124223602 Avg 0.006193152328371265\n",
      "Generation 53 Best 0.006211180124223602 Avg 0.006193441365613462\n",
      "Generation 54 Best 0.006211180124223602 Avg 0.006195797400321755\n",
      "Generation 55 Best 0.006211180124223602 Avg 0.00619426859100778\n",
      "Generation 56 Best 0.006211180124223602 Avg 0.006193964225608653\n",
      "Generation 57 Best 0.006211180124223602 Avg 0.006194045602818132\n",
      "Generation 58 Best 0.006211180124223602 Avg 0.00619559876954446\n",
      "Generation 59 Best 0.006211180124223602 Avg 0.006192639984729918\n",
      "Generation 60 Best 0.006211180124223602 Avg 0.006192553593637924\n",
      "Generation 61 Best 0.006211180124223602 Avg 0.006195945203390234\n",
      "Generation 62 Best 0.006211180124223602 Avg 0.006194017792160066\n",
      "Generation 63 Best 0.006211180124223602 Avg 0.0061945715774444085\n",
      "Generation 64 Best 0.006211180124223602 Avg 0.006193819127580124\n",
      "Generation 65 Best 0.006211180124223602 Avg 0.006194052437911407\n",
      "Generation 66 Best 0.006211180124223602 Avg 0.006195108202495879\n",
      "Generation 67 Best 0.006211180124223602 Avg 0.006193112468710871\n",
      "Generation 68 Best 0.006211180124223602 Avg 0.006193362424982022\n",
      "Generation 69 Best 0.006211180124223602 Avg 0.006195000125950834\n",
      "Generation 70 Best 0.006211180124223602 Avg 0.006194448207777946\n",
      "Generation 71 Best 0.006211180124223602 Avg 0.0061919610658218455\n",
      "Generation 72 Best 0.006211180124223602 Avg 0.006194879150669111\n",
      "Generation 73 Best 0.006211180124223602 Avg 0.006193263032936067\n",
      "Generation 74 Best 0.006211180124223602 Avg 0.006192873672708414\n",
      "Generation 75 Best 0.006211180124223602 Avg 0.00619597527260916\n",
      "Generation 76 Best 0.006211180124223602 Avg 0.006194020153153114\n",
      "Generation 77 Best 0.006211180124223602 Avg 0.006195069560441464\n",
      "Generation 78 Best 0.006211180124223602 Avg 0.006194510172946807\n",
      "Generation 79 Best 0.006211180124223602 Avg 0.006196581230136313\n",
      "Generation 80 Best 0.006211180124223602 Avg 0.006193291741231798\n",
      "Generation 81 Best 0.006211180124223602 Avg 0.006194483816823665\n",
      "Generation 82 Best 0.006211180124223602 Avg 0.006196331389171436\n",
      "Generation 83 Best 0.006211180124223602 Avg 0.0061961401309038825\n",
      "Generation 84 Best 0.006211180124223602 Avg 0.006196414100450629\n",
      "Generation 85 Best 0.006211180124223602 Avg 0.006194511928918094\n",
      "Generation 86 Best 0.006211180124223602 Avg 0.0061926068096940816\n",
      "Generation 87 Best 0.006211180124223602 Avg 0.0061937101863655825\n",
      "Generation 88 Best 0.006211180124223602 Avg 0.006193860727252411\n",
      "Generation 89 Best 0.006211180124223602 Avg 0.006195757288576083\n",
      "Generation 90 Best 0.00625 Avg 0.006194012737830734\n",
      "Generation 91 Best 0.00625 Avg 0.006180461997203618\n",
      "Generation 92 Best 0.00625 Avg 0.006211876552849538\n",
      "Generation 93 Best 0.00625 Avg 0.00622516636657478\n",
      "Generation 94 Best 0.00625 Avg 0.006224819709552221\n",
      "Generation 95 Best 0.00625 Avg 0.0062264622610803\n",
      "Generation 96 Best 0.00625 Avg 0.006227852398596169\n",
      "Generation 97 Best 0.00625 Avg 0.006231715410650227\n",
      "Generation 98 Best 0.00625 Avg 0.006226390772299451\n",
      "Generation 99 Best 0.00625 Avg 0.006223618152541665\n",
      "Generation 100 Best 0.00625 Avg 0.006225555378342866\n",
      "Generation 101 Best 0.00625 Avg 0.006224437723294882\n",
      "Generation 102 Best 0.00625 Avg 0.0062288677004584585\n",
      "Generation 103 Best 0.00625 Avg 0.006229058439361889\n",
      "Generation 104 Best 0.00625 Avg 0.006227470207827443\n",
      "Generation 105 Best 0.00625 Avg 0.006226553947647418\n",
      "Generation 106 Best 0.00625 Avg 0.006224174127105627\n",
      "Generation 107 Best 0.00625 Avg 0.006226537461300309\n",
      "Generation 108 Best 0.00625 Avg 0.006225844027428407\n",
      "Generation 109 Best 0.00625 Avg 0.006227500891527722\n",
      "Generation 110 Best 0.00625 Avg 0.006227138407760368\n",
      "Generation 111 Best 0.00625 Avg 0.006228030017066266\n",
      "Generation 112 Best 0.00625 Avg 0.0062257648990922555\n",
      "Generation 113 Best 0.00625 Avg 0.006221933709977582\n",
      "Generation 114 Best 0.00625 Avg 0.006226328350305748\n",
      "Generation 115 Best 0.00625 Avg 0.006227427451502367\n",
      "Generation 116 Best 0.00625 Avg 0.0062295335995192274\n",
      "Generation 117 Best 0.00625 Avg 0.006226004063802233\n",
      "Generation 118 Best 0.00625 Avg 0.006226797002407938\n",
      "Generation 119 Best 0.00625 Avg 0.006227079605074225\n",
      "Generation 120 Best 0.00625 Avg 0.0062253250249970785\n",
      "Generation 121 Best 0.00625 Avg 0.006225061756301835\n",
      "Generation 122 Best 0.00625 Avg 0.006223054222089534\n",
      "Generation 123 Best 0.00625 Avg 0.006226922906280329\n",
      "Generation 124 Best 0.00625 Avg 0.006223788410926743\n",
      "Generation 125 Best 0.00625 Avg 0.006226530848706749\n",
      "Generation 126 Best 0.00625 Avg 0.006226720894275752\n",
      "Generation 127 Best 0.00625 Avg 0.006222862511247761\n",
      "Generation 128 Best 0.00625 Avg 0.0062241847676924\n",
      "Generation 129 Best 0.00625 Avg 0.006228509674591429\n",
      "Generation 130 Best 0.00625 Avg 0.0062255168324427314\n",
      "Generation 131 Best 0.00625 Avg 0.0062250761003480705\n",
      "Generation 132 Best 0.00625 Avg 0.006226190489007539\n",
      "Generation 133 Best 0.00625 Avg 0.006225586874421089\n",
      "Generation 134 Best 0.00625 Avg 0.006227548703838754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 135 Best 0.00625 Avg 0.006227214130481018\n",
      "Generation 136 Best 0.00625 Avg 0.006228393949942786\n",
      "Generation 137 Best 0.00625 Avg 0.006225977279252109\n",
      "Generation 138 Best 0.00625 Avg 0.006225261388609555\n",
      "Generation 139 Best 0.00625 Avg 0.006226421455739897\n",
      "Generation 140 Best 0.00625 Avg 0.006227557308004638\n",
      "Generation 141 Best 0.00625 Avg 0.006224551343872178\n",
      "Generation 142 Best 0.00625 Avg 0.006228632575117505\n",
      "Generation 143 Best 0.00625 Avg 0.006229153356871291\n",
      "Generation 144 Best 0.00625 Avg 0.006224533848281062\n",
      "Generation 145 Best 0.00625 Avg 0.006226710646226176\n",
      "Generation 146 Best 0.00625 Avg 0.0062254151451184075\n",
      "Generation 147 Best 0.00625 Avg 0.006227398504539143\n",
      "Generation 148 Best 0.00625 Avg 0.006226459438875352\n",
      "Generation 149 Best 0.00625 Avg 0.006226379070328243\n",
      "Generation 150 Best 0.00625 Avg 0.006225373460818777\n",
      "Generation 151 Best 0.00625 Avg 0.006224978958706785\n",
      "Generation 152 Best 0.00625 Avg 0.006225663608992077\n",
      "Generation 153 Best 0.00625 Avg 0.0062262215505382796\n",
      "Generation 154 Best 0.00625 Avg 0.006226500619972118\n",
      "Generation 155 Best 0.00625 Avg 0.006227472208220462\n",
      "Generation 156 Best 0.00625 Avg 0.006228182118556124\n",
      "Generation 157 Best 0.00625 Avg 0.006227697692816318\n",
      "Generation 158 Best 0.00625 Avg 0.006224664851186274\n",
      "Generation 159 Best 0.00625 Avg 0.006225944995341333\n",
      "Generation 160 Best 0.00625 Avg 0.006227764579450422\n",
      "Generation 161 Best 0.00625 Avg 0.006223501645815237\n",
      "Generation 162 Best 0.00625 Avg 0.006228038662584217\n",
      "Generation 163 Best 0.00625 Avg 0.00622704826225265\n",
      "Generation 164 Best 0.00625 Avg 0.0062232978163662255\n",
      "Generation 165 Best 0.00625 Avg 0.006227461627461858\n",
      "Generation 166 Best 0.00625 Avg 0.006225239824639676\n",
      "Generation 167 Best 0.00625 Avg 0.006226364475821229\n",
      "Generation 168 Best 0.00625 Avg 0.0062266645739019015\n",
      "Generation 169 Best 0.00625 Avg 0.006224169302831713\n",
      "Generation 170 Best 0.00625 Avg 0.006230859392371243\n",
      "Generation 171 Best 0.00625 Avg 0.006224867247370227\n",
      "Generation 172 Best 0.00625 Avg 0.006229113194535383\n",
      "Generation 173 Best 0.00625 Avg 0.0062246058072903225\n",
      "Generation 174 Best 0.00625 Avg 0.0062257169016062585\n",
      "Generation 175 Best 0.00625 Avg 0.006226210275963286\n",
      "Generation 176 Best 0.00625 Avg 0.006228676083645417\n",
      "Generation 177 Best 0.00625 Avg 0.006227645331407988\n",
      "Generation 178 Best 0.00625 Avg 0.006226348897614474\n",
      "Generation 179 Best 0.00625 Avg 0.006228573985712231\n",
      "Generation 180 Best 0.00625 Avg 0.006228345960834638\n",
      "Generation 181 Best 0.00625 Avg 0.006229190670748785\n",
      "Generation 182 Best 0.00625 Avg 0.006228175113210228\n",
      "Generation 183 Best 0.00625 Avg 0.006226036210630423\n",
      "Generation 184 Best 0.00625 Avg 0.006224819383974902\n",
      "Generation 185 Best 0.00625 Avg 0.006226137221153887\n",
      "Generation 186 Best 0.00625 Avg 0.006225058086834317\n",
      "Generation 187 Best 0.00625 Avg 0.006226812049299876\n",
      "Generation 188 Best 0.00625 Avg 0.006223649197917431\n",
      "Generation 189 Best 0.00625 Avg 0.0062240348034567254\n",
      "Generation 190 Best 0.00625 Avg 0.006226932649248993\n",
      "Generation 191 Best 0.00625 Avg 0.006223560881227625\n",
      "Generation 192 Best 0.00625 Avg 0.006225193689995659\n",
      "Generation 193 Best 0.00625 Avg 0.006227297450974863\n",
      "Generation 194 Best 0.00625 Avg 0.006227809464854167\n",
      "Generation 195 Best 0.00625 Avg 0.006226830554028568\n",
      "Generation 196 Best 0.00625 Avg 0.006228504057200096\n",
      "Generation 197 Best 0.00625 Avg 0.006228364182609353\n",
      "Generation 198 Best 0.00625 Avg 0.006225523717076153\n",
      "Generation 199 Best 0.00625 Avg 0.006226697498932372\n",
      "Generation 200 Best 0.00625 Avg 0.006226603014927354\n",
      "Generation 201 Best 0.00625 Avg 0.006225233817687687\n",
      "Generation 202 Best 0.00625 Avg 0.006227406169430094\n",
      "Generation 203 Best 0.00625 Avg 0.006227082735866569\n",
      "Generation 204 Best 0.00625 Avg 0.006223895016534626\n",
      "Generation 205 Best 0.00625 Avg 0.006224481753254261\n",
      "Generation 206 Best 0.00625 Avg 0.006227845026933944\n",
      "Generation 207 Best 0.00625 Avg 0.006222509857756815\n",
      "Generation 208 Best 0.00625 Avg 0.006224637989577783\n",
      "Generation 209 Best 0.00625 Avg 0.006225783814063548\n",
      "Generation 210 Best 0.00625 Avg 0.006226315494401266\n",
      "Generation 211 Best 0.00625 Avg 0.006226147494166093\n",
      "Generation 212 Best 0.00625 Avg 0.006225920761373536\n",
      "Generation 213 Best 0.00625 Avg 0.006227243121939347\n",
      "Generation 214 Best 0.00625 Avg 0.006224529082165888\n",
      "Generation 215 Best 0.00625 Avg 0.006226798919223702\n",
      "Generation 216 Best 0.00625 Avg 0.006225292570194785\n",
      "Generation 217 Best 0.00625 Avg 0.006226415383294887\n",
      "Generation 218 Best 0.00625 Avg 0.006227153395671654\n",
      "Generation 219 Best 0.00625 Avg 0.006224691009323673\n",
      "Generation 220 Best 0.00625 Avg 0.00622710516616909\n",
      "Generation 221 Best 0.00625 Avg 0.006225258737492176\n",
      "Generation 222 Best 0.00625 Avg 0.0062235658864529\n",
      "Generation 223 Best 0.00625 Avg 0.006225049428929111\n",
      "Generation 224 Best 0.00625 Avg 0.006222320044406951\n",
      "Generation 225 Best 0.00625 Avg 0.006225851564525916\n",
      "Generation 226 Best 0.00625 Avg 0.006222866711808438\n",
      "Generation 227 Best 0.00625 Avg 0.0062220428225076355\n",
      "Generation 228 Best 0.00625 Avg 0.0062258776716428025\n",
      "Generation 229 Best 0.00625 Avg 0.006225740838134767\n",
      "Generation 230 Best 0.00625 Avg 0.006225650518996929\n",
      "Generation 231 Best 0.00625 Avg 0.00622742876918893\n",
      "Generation 232 Best 0.00625 Avg 0.006226480970503157\n",
      "Generation 233 Best 0.00625 Avg 0.006224906520654937\n",
      "Generation 234 Best 0.00625 Avg 0.006225592581618945\n",
      "Generation 235 Best 0.00625 Avg 0.006224681617357361\n",
      "Generation 236 Best 0.00625 Avg 0.006224192297430022\n",
      "Generation 237 Best 0.00625 Avg 0.006225890376428515\n",
      "Generation 238 Best 0.00625 Avg 0.006225938067041237\n",
      "Generation 239 Best 0.00625 Avg 0.0062262737912276165\n",
      "Generation 240 Best 0.00625 Avg 0.006226232182519496\n",
      "Generation 241 Best 0.00625 Avg 0.006228407185202317\n",
      "Generation 242 Best 0.00625 Avg 0.006227763005233556\n",
      "Generation 243 Best 0.00625 Avg 0.006226186237419829\n",
      "Generation 244 Best 0.00625 Avg 0.00622337402988434\n",
      "Generation 245 Best 0.00625 Avg 0.006228749788167734\n",
      "Generation 246 Best 0.00625 Avg 0.00622628035111215\n",
      "Generation 247 Best 0.00625 Avg 0.006227106104943447\n",
      "Generation 248 Best 0.00625 Avg 0.006227054678124988\n",
      "Generation 249 Best 0.00625 Avg 0.006226530028121401\n",
      "Generation 250 Best 0.00625 Avg 0.0062241306286762044\n",
      "Generation 251 Best 0.00625 Avg 0.00622634846304115\n",
      "Generation 252 Best 0.00625 Avg 0.006226078750766052\n",
      "Generation 253 Best 0.00625 Avg 0.006228587945820306\n",
      "Generation 254 Best 0.00625 Avg 0.006227124301945064\n",
      "Generation 255 Best 0.00625 Avg 0.006227710039056778\n",
      "Generation 256 Best 0.00625 Avg 0.006224210265570678\n",
      "Generation 257 Best 0.00625 Avg 0.0062262722680182245\n",
      "Generation 258 Best 0.00625 Avg 0.006222814743993912\n",
      "Generation 259 Best 0.00625 Avg 0.006229462982748439\n",
      "Generation 260 Best 0.00625 Avg 0.006223418946358885\n",
      "Generation 261 Best 0.00625 Avg 0.006227696804429625\n",
      "Generation 262 Best 0.00625 Avg 0.006224446841747486\n",
      "Generation 263 Best 0.00625 Avg 0.0062255124343324015\n",
      "Generation 264 Best 0.00625 Avg 0.006226006834784569\n",
      "Generation 265 Best 0.00625 Avg 0.0062283026582533145\n",
      "Generation 266 Best 0.00625 Avg 0.006224254564718838\n",
      "Generation 267 Best 0.00625 Avg 0.006226024099093921\n",
      "Generation 268 Best 0.00625 Avg 0.006227931997343746\n",
      "Generation 269 Best 0.00625 Avg 0.006225422613143295\n",
      "Generation 270 Best 0.00625 Avg 0.006227095446721806\n",
      "Generation 271 Best 0.00625 Avg 0.006224095059242589\n",
      "Generation 272 Best 0.00625 Avg 0.0062247643202330985\n",
      "Generation 273 Best 0.00625 Avg 0.006222714426002522\n",
      "Generation 274 Best 0.00625 Avg 0.006227834717804482\n",
      "Generation 275 Best 0.00625 Avg 0.006227307655983623\n",
      "Generation 276 Best 0.00625 Avg 0.006229228190572869\n",
      "Generation 277 Best 0.00625 Avg 0.006227575621734457\n",
      "Generation 278 Best 0.00625 Avg 0.006223020177149626\n",
      "Generation 279 Best 0.00625 Avg 0.0062254359409712225\n",
      "Generation 280 Best 0.00625 Avg 0.006228912422115433\n",
      "Generation 281 Best 0.00625 Avg 0.0062264042802442614\n",
      "Generation 282 Best 0.00625 Avg 0.006225200226182318\n",
      "Generation 283 Best 0.00625 Avg 0.006224550205310143\n",
      "Generation 284 Best 0.00625 Avg 0.006225090182629426\n",
      "Generation 285 Best 0.00625 Avg 0.0062268905438503785\n",
      "Generation 286 Best 0.00625 Avg 0.006228479125937812\n",
      "Generation 287 Best 0.00625 Avg 0.00622644449442864\n",
      "Generation 288 Best 0.00625 Avg 0.006225612544890789\n",
      "Generation 289 Best 0.00625 Avg 0.006225451819166335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 290 Best 0.00625 Avg 0.006223265088682602\n",
      "Generation 291 Best 0.00625 Avg 0.006226720517665352\n",
      "Generation 292 Best 0.00625 Avg 0.006226061872285947\n",
      "Generation 293 Best 0.00625 Avg 0.006224972979696774\n",
      "Generation 294 Best 0.00625 Avg 0.006228381914408514\n",
      "Generation 295 Best 0.00625 Avg 0.00622627473230378\n",
      "Generation 296 Best 0.00625 Avg 0.006225614813745955\n",
      "Generation 297 Best 0.00625 Avg 0.006225964898476998\n",
      "Generation 298 Best 0.00625 Avg 0.006228338364332719\n",
      "Generation 299 Best 0.00625 Avg 0.006226246263763803\n",
      "Generation 300 Best 0.00625 Avg 0.0062264131589478645\n",
      "Generation 301 Best 0.00625 Avg 0.006226465153837765\n",
      "Generation 302 Best 0.00625 Avg 0.006224816725106003\n",
      "Generation 303 Best 0.00625 Avg 0.006227526322267508\n",
      "Generation 304 Best 0.00625 Avg 0.0062286517547818126\n",
      "Generation 305 Best 0.00625 Avg 0.006225791222873559\n",
      "Generation 306 Best 0.00625 Avg 0.0062231631051518545\n",
      "Generation 307 Best 0.00625 Avg 0.006229592828767108\n",
      "Generation 308 Best 0.00625 Avg 0.006225567695408718\n",
      "Generation 309 Best 0.00625 Avg 0.006226575008212334\n",
      "Generation 310 Best 0.00625 Avg 0.006227858774153255\n",
      "Generation 311 Best 0.00625 Avg 0.0062243923670110245\n",
      "Generation 312 Best 0.00625 Avg 0.0062258791952759535\n",
      "Generation 313 Best 0.00625 Avg 0.006226953239578978\n",
      "Generation 314 Best 0.00625 Avg 0.006226009684083978\n",
      "Generation 315 Best 0.00625 Avg 0.006230944901309993\n",
      "Generation 316 Best 0.00625 Avg 0.0062264729713720724\n",
      "Generation 317 Best 0.00625 Avg 0.006226530336513216\n",
      "Generation 318 Best 0.00625 Avg 0.006224153348862312\n",
      "Generation 319 Best 0.00625 Avg 0.006225797033692933\n",
      "Generation 320 Best 0.00625 Avg 0.006226653075151483\n",
      "Generation 321 Best 0.00625 Avg 0.00622539552293996\n",
      "Generation 322 Best 0.00625 Avg 0.00622799751613133\n",
      "Generation 323 Best 0.00625 Avg 0.006224399330815321\n",
      "Generation 324 Best 0.00625 Avg 0.0062268887486011245\n",
      "Generation 325 Best 0.00625 Avg 0.006224164017201293\n",
      "Generation 326 Best 0.00625 Avg 0.006225855311241333\n",
      "Generation 327 Best 0.00625 Avg 0.006223868335055587\n",
      "Generation 328 Best 0.00625 Avg 0.006226646497208322\n",
      "Generation 329 Best 0.00625 Avg 0.006227673851815995\n",
      "Generation 330 Best 0.00625 Avg 0.006227948738741265\n",
      "Generation 331 Best 0.00625 Avg 0.006227468469484742\n",
      "Generation 332 Best 0.00625 Avg 0.006227952467815294\n",
      "Generation 333 Best 0.00625 Avg 0.006226527719818058\n",
      "Generation 334 Best 0.00625 Avg 0.006226940067296937\n",
      "Generation 335 Best 0.00625 Avg 0.006227580302198277\n",
      "Generation 336 Best 0.00625 Avg 0.00622427886670964\n",
      "Generation 337 Best 0.00625 Avg 0.006228024188574536\n",
      "Generation 338 Best 0.00625 Avg 0.006226241610818203\n",
      "Generation 339 Best 0.00625 Avg 0.006224353556601123\n",
      "Generation 340 Best 0.00625 Avg 0.006228436279276083\n",
      "Generation 341 Best 0.00625 Avg 0.006225886857366858\n",
      "Generation 342 Best 0.00625 Avg 0.006226076748507554\n",
      "Generation 343 Best 0.00625 Avg 0.006223096490387403\n",
      "Generation 344 Best 0.00625 Avg 0.006224847051044766\n",
      "Generation 345 Best 0.00625 Avg 0.006225833494004344\n",
      "Generation 346 Best 0.00625 Avg 0.0062268044280374265\n",
      "Generation 347 Best 0.00625 Avg 0.006226242318866355\n",
      "Generation 348 Best 0.00625 Avg 0.006224727382959484\n",
      "Generation 349 Best 0.00625 Avg 0.0062272252860320525\n",
      "Generation 350 Best 0.00625 Avg 0.006226309736189417\n",
      "Generation 351 Best 0.00625 Avg 0.0062254924517176164\n",
      "Generation 352 Best 0.00625 Avg 0.006222954042243387\n",
      "Generation 353 Best 0.00625 Avg 0.0062280398853814915\n",
      "Generation 354 Best 0.00625 Avg 0.006225784216066855\n",
      "Generation 355 Best 0.00625 Avg 0.006226567506391083\n",
      "Generation 356 Best 0.00625 Avg 0.0062259968693101405\n",
      "Generation 357 Best 0.00625 Avg 0.006228292206388981\n",
      "Generation 358 Best 0.00625 Avg 0.006224720855169761\n",
      "Generation 359 Best 0.00625 Avg 0.006227283748845097\n",
      "Generation 360 Best 0.00625 Avg 0.006225423057118244\n",
      "Generation 361 Best 0.00625 Avg 0.006225878247257143\n",
      "Generation 362 Best 0.00625 Avg 0.006227324432208035\n",
      "Generation 363 Best 0.00625 Avg 0.0062250291463708946\n",
      "Generation 364 Best 0.00625 Avg 0.006225317566431783\n",
      "Generation 365 Best 0.00625 Avg 0.006227025729909575\n",
      "Generation 366 Best 0.00625 Avg 0.006224994459691246\n",
      "Generation 367 Best 0.00625 Avg 0.0062259285881522955\n",
      "Generation 368 Best 0.00625 Avg 0.0062258599824607\n",
      "Generation 369 Best 0.00625 Avg 0.00622828744321451\n",
      "Generation 370 Best 0.00625 Avg 0.006223662603821687\n",
      "Generation 371 Best 0.00625 Avg 0.006223007464814494\n",
      "Generation 372 Best 0.00625 Avg 0.00622706411420082\n",
      "Generation 373 Best 0.00625 Avg 0.006226077297470279\n",
      "Generation 374 Best 0.00625 Avg 0.006226515068367232\n",
      "Generation 375 Best 0.00625 Avg 0.006225124921619949\n",
      "Generation 376 Best 0.00625 Avg 0.00622395349406116\n",
      "Generation 377 Best 0.00625 Avg 0.0062288998995588775\n",
      "Generation 378 Best 0.00625 Avg 0.006226799168836964\n",
      "Generation 379 Best 0.00625 Avg 0.006227181898848991\n",
      "Generation 380 Best 0.00625 Avg 0.006225530152056971\n",
      "Generation 381 Best 0.00625 Avg 0.006227425065722948\n",
      "Generation 382 Best 0.00625 Avg 0.006225741215130516\n",
      "Generation 383 Best 0.00625 Avg 0.006228073666887093\n",
      "Generation 384 Best 0.00625 Avg 0.006225632615667354\n",
      "Generation 385 Best 0.00625 Avg 0.006223503251399986\n",
      "Generation 386 Best 0.00625 Avg 0.006226723692554649\n",
      "Generation 387 Best 0.00625 Avg 0.006228454825016185\n",
      "Generation 388 Best 0.00625 Avg 0.006227381532017267\n",
      "Generation 389 Best 0.00625 Avg 0.006223652474189298\n",
      "Generation 390 Best 0.00625 Avg 0.00622347606632645\n",
      "Generation 391 Best 0.00625 Avg 0.006229167045565362\n",
      "Generation 392 Best 0.00625 Avg 0.006228257380084195\n",
      "Generation 393 Best 0.00625 Avg 0.006226927141289305\n",
      "Generation 394 Best 0.00625 Avg 0.006225866064150163\n",
      "Generation 395 Best 0.00625 Avg 0.006223406390227624\n",
      "Generation 396 Best 0.00625 Avg 0.006226235049238637\n",
      "Generation 397 Best 0.00625 Avg 0.006225883395002152\n",
      "Generation 398 Best 0.00625 Avg 0.006228858291274516\n",
      "Generation 399 Best 0.00625 Avg 0.006228124241423547\n",
      "Generation 400 Best 0.00625 Avg 0.006227104370787117\n",
      "Generation 401 Best 0.00625 Avg 0.006225041459402912\n",
      "Generation 402 Best 0.00625 Avg 0.006223965119599861\n",
      "Generation 403 Best 0.00625 Avg 0.006225240345679509\n",
      "Generation 404 Best 0.00625 Avg 0.006222217647345961\n",
      "Generation 405 Best 0.00625 Avg 0.006226610867744438\n",
      "Generation 406 Best 0.00625 Avg 0.006222306254722178\n",
      "Generation 407 Best 0.00625 Avg 0.006226026911649744\n",
      "Generation 408 Best 0.00625 Avg 0.006226631561999544\n",
      "Generation 409 Best 0.00625 Avg 0.006227047698798095\n",
      "Generation 410 Best 0.00625 Avg 0.006226910759910414\n",
      "Generation 411 Best 0.00625 Avg 0.006226477052048942\n",
      "Generation 412 Best 0.00625 Avg 0.006226873753140419\n",
      "Generation 413 Best 0.00625 Avg 0.006223251555762123\n",
      "Generation 414 Best 0.00625 Avg 0.0062264271283003925\n",
      "Generation 415 Best 0.00625 Avg 0.006227350632551302\n",
      "Generation 416 Best 0.00625 Avg 0.006225600938669424\n",
      "Generation 417 Best 0.00625 Avg 0.0062254022192872694\n",
      "Generation 418 Best 0.00625 Avg 0.0062264319187588565\n",
      "Generation 419 Best 0.00625 Avg 0.006228826109170069\n",
      "Generation 420 Best 0.00625 Avg 0.006222921143263574\n",
      "Generation 421 Best 0.00625 Avg 0.0062247811808697154\n",
      "Generation 422 Best 0.00625 Avg 0.006226050080237917\n",
      "Generation 423 Best 0.00625 Avg 0.006228065634168264\n",
      "Generation 424 Best 0.00625 Avg 0.006224653437859737\n",
      "Generation 425 Best 0.00625 Avg 0.006226658678639356\n",
      "Generation 426 Best 0.00625 Avg 0.006227453602494549\n",
      "Generation 427 Best 0.00625 Avg 0.006226651491266405\n",
      "Generation 428 Best 0.00625 Avg 0.006225642478096304\n",
      "Generation 429 Best 0.00625 Avg 0.0062274674943840385\n",
      "Generation 430 Best 0.00625 Avg 0.006226864509227176\n",
      "Generation 431 Best 0.00625 Avg 0.006223593406354257\n",
      "Generation 432 Best 0.00625 Avg 0.006228615364743999\n",
      "Generation 433 Best 0.00625 Avg 0.006227206714950018\n",
      "Generation 434 Best 0.00625 Avg 0.006226393021413523\n",
      "Generation 435 Best 0.00625 Avg 0.00622369245276076\n",
      "Generation 436 Best 0.00625 Avg 0.006225585908995117\n",
      "Generation 437 Best 0.00625 Avg 0.006226917678548818\n",
      "Generation 438 Best 0.00625 Avg 0.006226067056768022\n",
      "Generation 439 Best 0.00625 Avg 0.006224995399926412\n",
      "Generation 440 Best 0.00625 Avg 0.006226586641319541\n",
      "Generation 441 Best 0.00625 Avg 0.006224366233476983\n",
      "Generation 442 Best 0.00625 Avg 0.006223237517558632\n",
      "Generation 443 Best 0.00625 Avg 0.0062278057347240024\n",
      "Generation 444 Best 0.00625 Avg 0.00622568351307465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 445 Best 0.00625 Avg 0.00622258096008256\n",
      "Generation 446 Best 0.00625 Avg 0.006225480655502537\n",
      "Generation 447 Best 0.00625 Avg 0.006229340946727697\n",
      "Generation 448 Best 0.00625 Avg 0.006228055394313524\n",
      "Generation 449 Best 0.00625 Avg 0.006226200027718129\n",
      "Generation 450 Best 0.00625 Avg 0.006227291334015662\n",
      "Generation 451 Best 0.00625 Avg 0.006225662787141973\n",
      "Generation 452 Best 0.00625 Avg 0.006224977580370143\n",
      "Generation 453 Best 0.00625 Avg 0.006227277733508976\n",
      "Generation 454 Best 0.00625 Avg 0.006222428641770643\n",
      "Generation 455 Best 0.00625 Avg 0.006227199692177873\n",
      "Generation 456 Best 0.00625 Avg 0.006225718783360903\n",
      "Generation 457 Best 0.00625 Avg 0.006223991279393414\n",
      "Generation 458 Best 0.00625 Avg 0.006224345702962129\n",
      "Generation 459 Best 0.00625 Avg 0.00622367651208129\n",
      "Generation 460 Best 0.00625 Avg 0.0062257933957765455\n",
      "Generation 461 Best 0.00625 Avg 0.006222601046615947\n",
      "Generation 462 Best 0.00625 Avg 0.006227405536131983\n",
      "Generation 463 Best 0.00625 Avg 0.006227192024914819\n",
      "Generation 464 Best 0.00625 Avg 0.00622559538745378\n",
      "Generation 465 Best 0.00625 Avg 0.006228225634842074\n",
      "Generation 466 Best 0.00625 Avg 0.006226564923055963\n",
      "Generation 467 Best 0.00625 Avg 0.00622361213089551\n",
      "Generation 468 Best 0.00625 Avg 0.006226986840543939\n",
      "Generation 469 Best 0.00625 Avg 0.006223561625431677\n",
      "Generation 470 Best 0.00625 Avg 0.006228500205408872\n",
      "Generation 471 Best 0.00625 Avg 0.006220759091381041\n",
      "Generation 472 Best 0.00625 Avg 0.006224067566637795\n",
      "Generation 473 Best 0.00625 Avg 0.006226492064752647\n",
      "Generation 474 Best 0.00625 Avg 0.006225167454832019\n",
      "Generation 475 Best 0.00625 Avg 0.006225186188813305\n",
      "Generation 476 Best 0.00625 Avg 0.006225466611178074\n",
      "Generation 477 Best 0.00625 Avg 0.006225938538110646\n",
      "Generation 478 Best 0.00625 Avg 0.0062240999366171635\n",
      "Generation 479 Best 0.00625 Avg 0.0062251960946747035\n",
      "Generation 480 Best 0.00625 Avg 0.006226356649681366\n",
      "Generation 481 Best 0.00625 Avg 0.006225498628296367\n",
      "Generation 482 Best 0.00625 Avg 0.006223407861151747\n",
      "Generation 483 Best 0.00625 Avg 0.0062234673662279446\n",
      "Generation 484 Best 0.00625 Avg 0.006229405035082905\n",
      "Generation 485 Best 0.00625 Avg 0.006226291182748772\n",
      "Generation 486 Best 0.00625 Avg 0.006224026683840873\n",
      "Generation 487 Best 0.00625 Avg 0.006227390000529247\n",
      "Generation 488 Best 0.00625 Avg 0.006226204125214241\n",
      "Generation 489 Best 0.00625 Avg 0.0062250079054739565\n",
      "Generation 490 Best 0.00625 Avg 0.006225811779009028\n",
      "Generation 491 Best 0.00625 Avg 0.006224967515928588\n",
      "Generation 492 Best 0.00625 Avg 0.006225561484818466\n",
      "Generation 493 Best 0.00625 Avg 0.006226322492204261\n",
      "Generation 494 Best 0.00625 Avg 0.006225788886021466\n",
      "Generation 495 Best 0.00625 Avg 0.006223865990843608\n",
      "Generation 496 Best 0.00625 Avg 0.006224775257970011\n",
      "Generation 497 Best 0.00625 Avg 0.006225758475468399\n",
      "Generation 498 Best 0.00625 Avg 0.00622755159345318\n",
      "Generation 499 Best 0.00625 Avg 0.006225889853927873\n",
      "Generation 500 Best 0.00625 Avg 0.006224536192290941\n",
      "Generation 501 Best 0.00625 Avg 0.006221448259805781\n",
      "Generation 502 Best 0.00625 Avg 0.006222984326431696\n",
      "Generation 503 Best 0.00625 Avg 0.006228528186098606\n",
      "Generation 504 Best 0.00625 Avg 0.00622556016818804\n",
      "Generation 505 Best 0.00625 Avg 0.0062239548272703185\n",
      "Generation 506 Best 0.00625 Avg 0.006228675117163308\n",
      "Generation 507 Best 0.00625 Avg 0.006227933759448573\n",
      "Generation 508 Best 0.00625 Avg 0.006227741286558787\n",
      "Generation 509 Best 0.00625 Avg 0.006227037842065888\n",
      "Generation 510 Best 0.00625 Avg 0.006224067651650251\n",
      "Generation 511 Best 0.00625 Avg 0.006223713058258958\n",
      "Generation 512 Best 0.00625 Avg 0.006225600742795719\n",
      "Generation 513 Best 0.00625 Avg 0.006223584090592746\n",
      "Generation 514 Best 0.00625 Avg 0.006227050563430332\n",
      "Generation 515 Best 0.00625 Avg 0.006226729585091395\n",
      "Generation 516 Best 0.00625 Avg 0.006227857566499511\n",
      "Generation 517 Best 0.00625 Avg 0.006224922327899382\n",
      "Generation 518 Best 0.00625 Avg 0.0062243861148982595\n",
      "Generation 519 Best 0.00625 Avg 0.006226613897154213\n",
      "Generation 520 Best 0.00625 Avg 0.0062247418477312305\n",
      "Generation 521 Best 0.00625 Avg 0.006228832053776945\n",
      "Generation 522 Best 0.00625 Avg 0.0062284294595417134\n",
      "Generation 523 Best 0.00625 Avg 0.006222804384697973\n",
      "Generation 524 Best 0.00625 Avg 0.0062249532433117025\n",
      "Generation 525 Best 0.00625 Avg 0.006220603834047039\n",
      "Generation 526 Best 0.00625 Avg 0.006222037560138764\n",
      "Generation 527 Best 0.00625 Avg 0.006226990639538105\n",
      "Generation 528 Best 0.00625 Avg 0.006226412732601267\n",
      "Generation 529 Best 0.00625 Avg 0.006225178267569017\n",
      "Generation 530 Best 0.00625 Avg 0.006224398177716526\n",
      "Generation 531 Best 0.00625 Avg 0.006230088360947607\n",
      "Generation 532 Best 0.00625 Avg 0.006227889430550452\n",
      "Generation 533 Best 0.00625 Avg 0.006226365982249787\n",
      "Generation 534 Best 0.00625 Avg 0.006226070001589097\n",
      "Generation 535 Best 0.00625 Avg 0.006228967343337504\n",
      "Generation 536 Best 0.00625 Avg 0.006227810807738057\n",
      "Generation 537 Best 0.00625 Avg 0.0062218842667326624\n",
      "Generation 538 Best 0.00625 Avg 0.006228303214980598\n",
      "Generation 539 Best 0.00625 Avg 0.006226750184033455\n",
      "Generation 540 Best 0.00625 Avg 0.00622786423912334\n",
      "Generation 541 Best 0.00625 Avg 0.00622798988540929\n",
      "Generation 542 Best 0.00625 Avg 0.006226658722097411\n",
      "Generation 543 Best 0.00625 Avg 0.006226023602429032\n",
      "Generation 544 Best 0.00625 Avg 0.0062240777544289244\n",
      "Generation 545 Best 0.00625 Avg 0.006224641384899215\n",
      "Generation 546 Best 0.00625 Avg 0.006223589701630039\n",
      "Generation 547 Best 0.00625 Avg 0.006229331467636655\n",
      "Generation 548 Best 0.00625 Avg 0.006229490057840369\n",
      "Generation 549 Best 0.00625 Avg 0.006227662201491158\n",
      "Generation 550 Best 0.00625 Avg 0.006225817757412267\n",
      "Generation 551 Best 0.00625 Avg 0.006228106789839997\n",
      "Generation 552 Best 0.00625 Avg 0.006227965103300678\n",
      "Generation 553 Best 0.00625 Avg 0.006231007990006067\n",
      "Generation 554 Best 0.00625 Avg 0.006225381117579143\n",
      "Generation 555 Best 0.00625 Avg 0.006226623588476506\n",
      "Generation 556 Best 0.00625 Avg 0.006225057932116861\n",
      "Generation 557 Best 0.00625 Avg 0.006223114138654001\n",
      "Generation 558 Best 0.00625 Avg 0.006224572993127385\n",
      "Generation 559 Best 0.00625 Avg 0.006229055118594918\n",
      "Generation 560 Best 0.00625 Avg 0.006225614530987794\n",
      "Generation 561 Best 0.00625 Avg 0.006224187233470888\n",
      "Generation 562 Best 0.00625 Avg 0.006228524926614092\n",
      "Generation 563 Best 0.00625 Avg 0.006227006491284174\n",
      "Generation 564 Best 0.00625 Avg 0.006223551249961206\n",
      "Generation 565 Best 0.00625 Avg 0.006228129303719773\n",
      "Generation 566 Best 0.00625 Avg 0.006228760660517761\n",
      "Generation 567 Best 0.00625 Avg 0.0062249218826531585\n",
      "Generation 568 Best 0.00625 Avg 0.0062229616477746195\n",
      "Generation 569 Best 0.00625 Avg 0.0062274699933265116\n",
      "Generation 570 Best 0.00625 Avg 0.006226181233061157\n",
      "Generation 571 Best 0.00625 Avg 0.006222323988001233\n",
      "Generation 572 Best 0.00625 Avg 0.006228722158233323\n",
      "Generation 573 Best 0.00625 Avg 0.006226802718002729\n",
      "Generation 574 Best 0.00625 Avg 0.0062256645064146035\n",
      "Generation 575 Best 0.00625 Avg 0.006222645666244935\n",
      "Generation 576 Best 0.00625 Avg 0.00622611081674255\n",
      "Generation 577 Best 0.00625 Avg 0.006223608444432019\n",
      "Generation 578 Best 0.00625 Avg 0.006225155751589535\n",
      "Generation 579 Best 0.00625 Avg 0.0062250226964554005\n",
      "Generation 580 Best 0.00625 Avg 0.006225668038154119\n",
      "Generation 581 Best 0.00625 Avg 0.006227360060211111\n",
      "Generation 582 Best 0.00625 Avg 0.006228031520130128\n",
      "Generation 583 Best 0.00625 Avg 0.006226824028344835\n",
      "Generation 584 Best 0.00625 Avg 0.006224306473109867\n",
      "Generation 585 Best 0.00625 Avg 0.006227260094473791\n",
      "Generation 586 Best 0.00625 Avg 0.006228432258851376\n",
      "Generation 587 Best 0.00625 Avg 0.0062276204638952865\n",
      "Generation 588 Best 0.00625 Avg 0.006227213763545349\n",
      "Generation 589 Best 0.00625 Avg 0.0062254054796193\n",
      "Generation 590 Best 0.00625 Avg 0.00622592266788871\n",
      "Generation 591 Best 0.00625 Avg 0.006229532154626909\n",
      "Generation 592 Best 0.00625 Avg 0.006225285829580078\n",
      "Generation 593 Best 0.00625 Avg 0.006226624607661123\n",
      "Generation 594 Best 0.00625 Avg 0.006227302174264359\n",
      "Generation 595 Best 0.00625 Avg 0.006224659246648783\n",
      "Generation 596 Best 0.00625 Avg 0.006224438459512718\n",
      "Generation 597 Best 0.00625 Avg 0.006226787712254474\n",
      "Generation 598 Best 0.00625 Avg 0.006226364356993321\n",
      "Generation 599 Best 0.00625 Avg 0.006227183283085183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 600 Best 0.00625 Avg 0.006226573826760841\n",
      "Generation 601 Best 0.00625 Avg 0.0062258207179710775\n",
      "Generation 602 Best 0.00625 Avg 0.0062256632991078\n",
      "Generation 603 Best 0.00625 Avg 0.006225664035971053\n",
      "Generation 604 Best 0.00625 Avg 0.006227328666173443\n",
      "Generation 605 Best 0.00625 Avg 0.006226235955683957\n",
      "Generation 606 Best 0.00625 Avg 0.006227338527729269\n",
      "Generation 607 Best 0.00625 Avg 0.0062256185279234814\n",
      "Generation 608 Best 0.00625 Avg 0.00622591096634778\n",
      "Generation 609 Best 0.00625 Avg 0.006227312283529796\n",
      "Generation 610 Best 0.00625 Avg 0.0062249593348845155\n",
      "Generation 611 Best 0.00625 Avg 0.006226465007510726\n",
      "Generation 612 Best 0.00625 Avg 0.006226863958544941\n",
      "Generation 613 Best 0.00625 Avg 0.006226279428929092\n",
      "Generation 614 Best 0.00625 Avg 0.006226487489054946\n",
      "Generation 615 Best 0.00625 Avg 0.0062255981072200225\n",
      "Generation 616 Best 0.00625 Avg 0.006224412179202508\n",
      "Generation 617 Best 0.00625 Avg 0.006227809951869932\n",
      "Generation 618 Best 0.00625 Avg 0.00622369149810149\n",
      "Generation 619 Best 0.00625 Avg 0.006224825485607558\n",
      "Generation 620 Best 0.00625 Avg 0.006228244395278924\n",
      "Generation 621 Best 0.00625 Avg 0.00622636739397812\n",
      "Generation 622 Best 0.00625 Avg 0.006229501177684867\n",
      "Generation 623 Best 0.00625 Avg 0.006224941558571164\n",
      "Generation 624 Best 0.00625 Avg 0.006229480621561966\n",
      "Generation 625 Best 0.00625 Avg 0.006223277269918054\n",
      "Generation 626 Best 0.00625 Avg 0.006228506192215566\n",
      "Generation 627 Best 0.00625 Avg 0.006225512999019823\n",
      "Generation 628 Best 0.00625 Avg 0.006228485217504106\n",
      "Generation 629 Best 0.00625 Avg 0.006224303632207394\n",
      "Generation 630 Best 0.00625 Avg 0.006226436145781616\n",
      "Generation 631 Best 0.00625 Avg 0.00622751012101202\n",
      "Generation 632 Best 0.00625 Avg 0.006225309515432668\n",
      "Generation 633 Best 0.00625 Avg 0.006228291555619927\n",
      "Generation 634 Best 0.00625 Avg 0.006230798570215491\n",
      "Generation 635 Best 0.00625 Avg 0.006226945344790253\n",
      "Generation 636 Best 0.00625 Avg 0.006221406154824641\n",
      "Generation 637 Best 0.00625 Avg 0.0062244027695948076\n",
      "Generation 638 Best 0.00625 Avg 0.006227735024518451\n",
      "Generation 639 Best 0.00625 Avg 0.006229007915004479\n",
      "Generation 640 Best 0.00625 Avg 0.0062283841828590075\n",
      "Generation 641 Best 0.00625 Avg 0.006228075155243986\n",
      "Generation 642 Best 0.00625 Avg 0.006226972324562617\n",
      "Generation 643 Best 0.00625 Avg 0.006226118607037557\n",
      "Generation 644 Best 0.00625 Avg 0.006228083205389065\n",
      "Generation 645 Best 0.00625 Avg 0.006226014644352218\n",
      "Generation 646 Best 0.00625 Avg 0.006230785840238971\n",
      "Generation 647 Best 0.00625 Avg 0.006224795482311932\n",
      "Generation 648 Best 0.00625 Avg 0.006223182820752498\n",
      "Generation 649 Best 0.00625 Avg 0.006226352962363839\n",
      "Generation 650 Best 0.00625 Avg 0.006225312028735691\n",
      "Generation 651 Best 0.00625 Avg 0.006223961442152881\n",
      "Generation 652 Best 0.00625 Avg 0.006224735792080092\n",
      "Generation 653 Best 0.00625 Avg 0.006227152096252339\n",
      "Generation 654 Best 0.00625 Avg 0.006224618375391836\n",
      "Generation 655 Best 0.00625 Avg 0.00622570289007347\n",
      "Generation 656 Best 0.00625 Avg 0.006229091663109678\n",
      "Generation 657 Best 0.00625 Avg 0.00622550492283642\n",
      "Generation 658 Best 0.00625 Avg 0.006228135900575598\n",
      "Generation 659 Best 0.00625 Avg 0.006226053961335728\n",
      "Generation 660 Best 0.00625 Avg 0.006228625014113503\n",
      "Generation 661 Best 0.00625 Avg 0.006227395620817512\n",
      "Generation 662 Best 0.00625 Avg 0.0062270829504121935\n",
      "Generation 663 Best 0.00625 Avg 0.006226339658885723\n",
      "Generation 664 Best 0.00625 Avg 0.006225450166430295\n",
      "Generation 665 Best 0.00625 Avg 0.006224306490751255\n",
      "Generation 666 Best 0.00625 Avg 0.006229522684748194\n",
      "Generation 667 Best 0.00625 Avg 0.006224116643168702\n",
      "Generation 668 Best 0.00625 Avg 0.006224461622232288\n",
      "Generation 669 Best 0.00625 Avg 0.006224605919182102\n",
      "Generation 670 Best 0.00625 Avg 0.006225986561628448\n",
      "Generation 671 Best 0.00625 Avg 0.0062252847339950785\n",
      "Generation 672 Best 0.00625 Avg 0.006226523408623839\n",
      "Generation 673 Best 0.00625 Avg 0.006226521141229481\n",
      "Generation 674 Best 0.00625 Avg 0.006224278919595161\n",
      "Generation 675 Best 0.00625 Avg 0.0062263444338085516\n",
      "Generation 676 Best 0.00625 Avg 0.006227081530912783\n",
      "Generation 677 Best 0.00625 Avg 0.006222639489881324\n",
      "Generation 678 Best 0.00625 Avg 0.006226556205158426\n",
      "Generation 679 Best 0.00625 Avg 0.006227563929007702\n",
      "Generation 680 Best 0.00625 Avg 0.006225820640077762\n",
      "Generation 681 Best 0.00625 Avg 0.006223809412080729\n",
      "Generation 682 Best 0.00625 Avg 0.0062286936703888135\n",
      "Generation 683 Best 0.00625 Avg 0.006228731062557777\n",
      "Generation 684 Best 0.00625 Avg 0.0062249238685350245\n",
      "Generation 685 Best 0.00625 Avg 0.006227004088040096\n",
      "Generation 686 Best 0.00625 Avg 0.00622773079061054\n",
      "Generation 687 Best 0.00625 Avg 0.006225460818367274\n",
      "Generation 688 Best 0.00625 Avg 0.006226071771445443\n",
      "Generation 689 Best 0.00625 Avg 0.0062268451808839415\n",
      "Generation 690 Best 0.00625 Avg 0.0062295882188558045\n",
      "Generation 691 Best 0.00625 Avg 0.006222199034703006\n",
      "Generation 692 Best 0.00625 Avg 0.006222871920842424\n",
      "Generation 693 Best 0.00625 Avg 0.006229117883181\n",
      "Generation 694 Best 0.00625 Avg 0.006226662425987151\n",
      "Generation 695 Best 0.00625 Avg 0.006223395329970785\n",
      "Generation 696 Best 0.00625 Avg 0.006225015041630815\n",
      "Generation 697 Best 0.00625 Avg 0.006227570635851652\n",
      "Generation 698 Best 0.00625 Avg 0.0062225011839562305\n",
      "Generation 699 Best 0.00625 Avg 0.006225970727549374\n",
      "Generation 700 Best 0.00625 Avg 0.0062253961304786646\n",
      "Generation 701 Best 0.00625 Avg 0.0062252291488022506\n",
      "Generation 702 Best 0.00625 Avg 0.006227047628492607\n",
      "Generation 703 Best 0.00625 Avg 0.006227712843835477\n",
      "Generation 704 Best 0.00625 Avg 0.006227226709078937\n",
      "Generation 705 Best 0.00625 Avg 0.006225527405841449\n",
      "Generation 706 Best 0.00625 Avg 0.00622628646073707\n",
      "Generation 707 Best 0.00625 Avg 0.006224954339965877\n",
      "Generation 708 Best 0.00625 Avg 0.0062262991115555185\n",
      "Generation 709 Best 0.00625 Avg 0.006226692477779828\n",
      "Generation 710 Best 0.00625 Avg 0.006228193907652062\n",
      "Generation 711 Best 0.00625 Avg 0.006223543756935279\n",
      "Generation 712 Best 0.00625 Avg 0.006226234989195329\n",
      "Generation 713 Best 0.00625 Avg 0.00622716939204321\n",
      "Generation 714 Best 0.00625 Avg 0.006223628171350979\n",
      "Generation 715 Best 0.00625 Avg 0.0062264132370498\n",
      "Generation 716 Best 0.00625 Avg 0.006227692936793114\n",
      "Generation 717 Best 0.00625 Avg 0.006227555212564454\n",
      "Generation 718 Best 0.00625 Avg 0.006228123308105423\n",
      "Generation 719 Best 0.00625 Avg 0.00622703750955896\n",
      "Generation 720 Best 0.00625 Avg 0.006222569207103877\n",
      "Generation 721 Best 0.00625 Avg 0.006226551046290918\n",
      "Generation 722 Best 0.00625 Avg 0.006227496639731393\n",
      "Generation 723 Best 0.00625 Avg 0.006226317256708193\n",
      "Generation 724 Best 0.00625 Avg 0.006224262161637996\n",
      "Generation 725 Best 0.00625 Avg 0.006228512763880583\n",
      "Generation 726 Best 0.00625 Avg 0.006225720991318725\n",
      "Generation 727 Best 0.00625 Avg 0.006228367826879544\n",
      "Generation 728 Best 0.00625 Avg 0.006224999780585121\n",
      "Generation 729 Best 0.00625 Avg 0.006226035792054901\n",
      "Generation 730 Best 0.00625 Avg 0.006222270591076582\n",
      "Generation 731 Best 0.00625 Avg 0.006227487306745732\n",
      "Generation 732 Best 0.00625 Avg 0.006227646273344706\n",
      "Generation 733 Best 0.00625 Avg 0.0062232846430471354\n",
      "Generation 734 Best 0.00625 Avg 0.006222919920225789\n",
      "Generation 735 Best 0.00625 Avg 0.006227993307369299\n",
      "Generation 736 Best 0.00625 Avg 0.00622574242766561\n",
      "Generation 737 Best 0.00625 Avg 0.006224220398427558\n",
      "Generation 738 Best 0.00625 Avg 0.0062273376473092334\n",
      "Generation 739 Best 0.00625 Avg 0.006225757919373493\n",
      "Generation 740 Best 0.00625 Avg 0.006228511822974395\n",
      "Generation 741 Best 0.00625 Avg 0.006225932018724379\n",
      "Generation 742 Best 0.00625 Avg 0.00622770790728467\n",
      "Generation 743 Best 0.00625 Avg 0.006228203701628201\n",
      "Generation 744 Best 0.00625 Avg 0.0062256396231320415\n",
      "Generation 745 Best 0.00625 Avg 0.006228555911946551\n",
      "Generation 746 Best 0.00625 Avg 0.0062255521532936136\n",
      "Generation 747 Best 0.00625 Avg 0.006228893031073911\n",
      "Generation 748 Best 0.00625 Avg 0.006227394595329144\n",
      "Generation 749 Best 0.00625 Avg 0.006226524170190362\n",
      "Generation 750 Best 0.00625 Avg 0.00622559759226228\n",
      "Generation 751 Best 0.00625 Avg 0.0062245950031654\n",
      "Generation 752 Best 0.00625 Avg 0.006227766308176125\n",
      "Generation 753 Best 0.00625 Avg 0.006224213059088321\n",
      "Generation 754 Best 0.00625 Avg 0.006226099386230039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 755 Best 0.00625 Avg 0.006221499738896706\n",
      "Generation 756 Best 0.00625 Avg 0.006224905632476863\n",
      "Generation 757 Best 0.00625 Avg 0.006224614149640116\n",
      "Generation 758 Best 0.00625 Avg 0.0062270799902771415\n",
      "Generation 759 Best 0.00625 Avg 0.006227384765469976\n",
      "Generation 760 Best 0.00625 Avg 0.006227074258533895\n",
      "Generation 761 Best 0.00625 Avg 0.006226423964135443\n",
      "Generation 762 Best 0.00625 Avg 0.006223518195638079\n",
      "Generation 763 Best 0.00625 Avg 0.0062239052729681\n",
      "Generation 764 Best 0.00625 Avg 0.0062290223214023464\n",
      "Generation 765 Best 0.00625 Avg 0.006223524688770882\n",
      "Generation 766 Best 0.00625 Avg 0.006226771348093213\n",
      "Generation 767 Best 0.00625 Avg 0.006223421213753243\n",
      "Generation 768 Best 0.00625 Avg 0.006225326727267218\n",
      "Generation 769 Best 0.00625 Avg 0.006228791183601505\n",
      "Generation 770 Best 0.00625 Avg 0.006225091704808288\n",
      "Generation 771 Best 0.00625 Avg 0.006227030358916556\n",
      "Generation 772 Best 0.00625 Avg 0.006226456572788589\n",
      "Generation 773 Best 0.00625 Avg 0.006227890722003109\n",
      "Generation 774 Best 0.00625 Avg 0.0062259086055505486\n",
      "Generation 775 Best 0.00625 Avg 0.006223609847776455\n",
      "Generation 776 Best 0.00625 Avg 0.006222178247436661\n",
      "Generation 777 Best 0.00625 Avg 0.006224939291607084\n",
      "Generation 778 Best 0.00625 Avg 0.006225436719154652\n",
      "Generation 779 Best 0.00625 Avg 0.0062273268515812465\n",
      "Generation 780 Best 0.00625 Avg 0.0062282663719508535\n",
      "Generation 781 Best 0.00625 Avg 0.006229402631668615\n",
      "Generation 782 Best 0.00625 Avg 0.00622834340334179\n",
      "Generation 783 Best 0.00625 Avg 0.006221952086052513\n",
      "Generation 784 Best 0.00625 Avg 0.006226735001336725\n",
      "Generation 785 Best 0.00625 Avg 0.00622867222545546\n",
      "Generation 786 Best 0.00625 Avg 0.0062244878507005455\n",
      "Generation 787 Best 0.00625 Avg 0.0062254394479436875\n",
      "Generation 788 Best 0.00625 Avg 0.006224214436185813\n",
      "Generation 789 Best 0.00625 Avg 0.006223999233207719\n",
      "Generation 790 Best 0.00625 Avg 0.006225757510035906\n",
      "Generation 791 Best 0.00625 Avg 0.006226205851397393\n",
      "Generation 792 Best 0.00625 Avg 0.006226139490185783\n",
      "Generation 793 Best 0.00625 Avg 0.006228385063272524\n",
      "Generation 794 Best 0.00625 Avg 0.006225033732369185\n",
      "Generation 795 Best 0.00625 Avg 0.006222187451331998\n",
      "Generation 796 Best 0.00625 Avg 0.00622803218792076\n",
      "Generation 797 Best 0.00625 Avg 0.006225268693096293\n",
      "Generation 798 Best 0.00625 Avg 0.0062243757459406295\n",
      "Generation 799 Best 0.00625 Avg 0.006224165394722544\n",
      "Generation 800 Best 0.00625 Avg 0.0062249724397633625\n",
      "Generation 801 Best 0.00625 Avg 0.0062275135782482866\n",
      "Generation 802 Best 0.00625 Avg 0.006225576789903616\n",
      "Generation 803 Best 0.00625 Avg 0.0062283379803945585\n",
      "Generation 804 Best 0.00625 Avg 0.0062270359355188236\n",
      "Generation 805 Best 0.00625 Avg 0.006228200296455544\n",
      "Generation 806 Best 0.00625 Avg 0.006226576788982561\n",
      "Generation 807 Best 0.00625 Avg 0.0062277014143409274\n",
      "Generation 808 Best 0.00625 Avg 0.00622818122996081\n",
      "Generation 809 Best 0.00625 Avg 0.006229618219432387\n",
      "Generation 810 Best 0.00625 Avg 0.006227687871119859\n",
      "Generation 811 Best 0.00625 Avg 0.006227571344330082\n",
      "Generation 812 Best 0.00625 Avg 0.006224089619723144\n",
      "Generation 813 Best 0.00625 Avg 0.006226478806199442\n",
      "Generation 814 Best 0.00625 Avg 0.006224984107305829\n",
      "Generation 815 Best 0.00625 Avg 0.006227404373130987\n",
      "Generation 816 Best 0.00625 Avg 0.006229525643422439\n",
      "Generation 817 Best 0.00625 Avg 0.00622581038301843\n",
      "Generation 818 Best 0.00625 Avg 0.006225688765996967\n",
      "Generation 819 Best 0.00625 Avg 0.006223080390312384\n",
      "Generation 820 Best 0.00625 Avg 0.00622700102444861\n",
      "Generation 821 Best 0.00625 Avg 0.00622651069565633\n",
      "Generation 822 Best 0.00625 Avg 0.006226191334562036\n",
      "Generation 823 Best 0.00625 Avg 0.006226882692519708\n",
      "Generation 824 Best 0.00625 Avg 0.006223450983173342\n",
      "Generation 825 Best 0.00625 Avg 0.006227908549956313\n",
      "Generation 826 Best 0.00625 Avg 0.006223152906459648\n",
      "Generation 827 Best 0.00625 Avg 0.006226771620146114\n",
      "Generation 828 Best 0.00625 Avg 0.00622623215690493\n",
      "Generation 829 Best 0.00625 Avg 0.006226261721473223\n",
      "Generation 830 Best 0.00625 Avg 0.006226667924708907\n",
      "Generation 831 Best 0.00625 Avg 0.006225148975869016\n",
      "Generation 832 Best 0.00625 Avg 0.006226833171381474\n",
      "Generation 833 Best 0.00625 Avg 0.006222530061214456\n",
      "Generation 834 Best 0.00625 Avg 0.006229408303805352\n",
      "Generation 835 Best 0.00625 Avg 0.006223362924962186\n",
      "Generation 836 Best 0.00625 Avg 0.006222137947784177\n",
      "Generation 837 Best 0.00625 Avg 0.006224802138141888\n",
      "Generation 838 Best 0.00625 Avg 0.006225195023843715\n",
      "Generation 839 Best 0.00625 Avg 0.006227178126114808\n",
      "Generation 840 Best 0.00625 Avg 0.006227706546550773\n",
      "Generation 841 Best 0.00625 Avg 0.00622755651156653\n",
      "Generation 842 Best 0.00625 Avg 0.006221661989342571\n",
      "Generation 843 Best 0.00625 Avg 0.006227570960176783\n",
      "Generation 844 Best 0.00625 Avg 0.006222683520055841\n",
      "Generation 845 Best 0.00625 Avg 0.006226898526630908\n",
      "Generation 846 Best 0.00625 Avg 0.006226314971900624\n",
      "Generation 847 Best 0.00625 Avg 0.006227287263196771\n",
      "Generation 848 Best 0.00625 Avg 0.006226943846765149\n",
      "Generation 849 Best 0.00625 Avg 0.006223777710290143\n",
      "Generation 850 Best 0.00625 Avg 0.006227206008678412\n",
      "Generation 851 Best 0.00625 Avg 0.006223366697487751\n",
      "Generation 852 Best 0.00625 Avg 0.006224393050767334\n",
      "Generation 853 Best 0.00625 Avg 0.006227800209970442\n",
      "Generation 854 Best 0.00625 Avg 0.006225729126078108\n",
      "Generation 855 Best 0.00625 Avg 0.006228166626000724\n",
      "Generation 856 Best 0.00625 Avg 0.0062273759373435685\n",
      "Generation 857 Best 0.00625 Avg 0.006225992309558795\n",
      "Generation 858 Best 0.00625 Avg 0.006227649147828405\n",
      "Generation 859 Best 0.00625 Avg 0.006223576082640967\n",
      "Generation 860 Best 0.00625 Avg 0.006224162964650591\n",
      "Generation 861 Best 0.00625 Avg 0.006227103386454999\n",
      "Generation 862 Best 0.00625 Avg 0.006225161433160257\n",
      "Generation 863 Best 0.00625 Avg 0.006228226497829341\n",
      "Generation 864 Best 0.00625 Avg 0.006225955792751786\n",
      "Generation 865 Best 0.00625 Avg 0.006229326395261498\n",
      "Generation 866 Best 0.00625 Avg 0.006225393195104143\n",
      "Generation 867 Best 0.00625 Avg 0.006222044431785621\n",
      "Generation 868 Best 0.00625 Avg 0.006227077227483122\n",
      "Generation 869 Best 0.00625 Avg 0.006226068965819227\n",
      "Generation 870 Best 0.00625 Avg 0.006226328608948324\n",
      "Generation 871 Best 0.00625 Avg 0.006228447801187903\n",
      "Generation 872 Best 0.00625 Avg 0.00622761317682176\n",
      "Generation 873 Best 0.00625 Avg 0.00622762408314488\n",
      "Generation 874 Best 0.00625 Avg 0.006229705688214678\n",
      "Generation 875 Best 0.00625 Avg 0.006227007996852178\n",
      "Generation 876 Best 0.00625 Avg 0.006223379708957205\n",
      "Generation 877 Best 0.00625 Avg 0.006227640756772943\n",
      "Generation 878 Best 0.00625 Avg 0.006226800322144379\n",
      "Generation 879 Best 0.00625 Avg 0.006226065132833117\n",
      "Generation 880 Best 0.00625 Avg 0.006225352989114599\n",
      "Generation 881 Best 0.00625 Avg 0.0062240451281343895\n",
      "Generation 882 Best 0.00625 Avg 0.006224414677499565\n",
      "Generation 883 Best 0.00625 Avg 0.006227260837394001\n",
      "Generation 884 Best 0.00625 Avg 0.006226237358819774\n",
      "Generation 885 Best 0.00625 Avg 0.006223789693330528\n",
      "Generation 886 Best 0.00625 Avg 0.006227422500048304\n",
      "Generation 887 Best 0.00625 Avg 0.006224711772391803\n",
      "Generation 888 Best 0.00625 Avg 0.006226546855594033\n",
      "Generation 889 Best 0.00625 Avg 0.006229894439573335\n",
      "Generation 890 Best 0.00625 Avg 0.006225049661356633\n",
      "Generation 891 Best 0.00625 Avg 0.006229406464876385\n",
      "Generation 892 Best 0.00625 Avg 0.006227097338346761\n",
      "Generation 893 Best 0.00625 Avg 0.006225756696797877\n",
      "Generation 894 Best 0.00625 Avg 0.006229005246675989\n",
      "Generation 895 Best 0.00625 Avg 0.006227260590740527\n",
      "Generation 896 Best 0.00625 Avg 0.00622455255728668\n",
      "Generation 897 Best 0.00625 Avg 0.006224912165514199\n",
      "Generation 898 Best 0.00625 Avg 0.006227882127119851\n",
      "Generation 899 Best 0.00625 Avg 0.006225596233862314\n",
      "Generation 900 Best 0.00625 Avg 0.006224469074108721\n",
      "Generation 901 Best 0.00625 Avg 0.006223442771817525\n",
      "Generation 902 Best 0.00625 Avg 0.006227461395698603\n",
      "Generation 903 Best 0.00625 Avg 0.006220906398827964\n",
      "Generation 904 Best 0.00625 Avg 0.006224832977147307\n",
      "Generation 905 Best 0.00625 Avg 0.006225769150907671\n",
      "Generation 906 Best 0.00625 Avg 0.006225834078115473\n",
      "Generation 907 Best 0.00625 Avg 0.006224420931300844\n",
      "Generation 908 Best 0.00625 Avg 0.0062260171689027385\n",
      "Generation 909 Best 0.00625 Avg 0.006226469276733304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 910 Best 0.00625 Avg 0.006228305523916318\n",
      "Generation 911 Best 0.00625 Avg 0.006228149980763768\n",
      "Generation 912 Best 0.00625 Avg 0.0062264041945994265\n",
      "Generation 913 Best 0.00625 Avg 0.006224957085561825\n",
      "Generation 914 Best 0.00625 Avg 0.006226045749511459\n",
      "Generation 915 Best 0.00625 Avg 0.006228047062460372\n",
      "Generation 916 Best 0.00625 Avg 0.006226208803559268\n",
      "Generation 917 Best 0.00625 Avg 0.006224800736068728\n",
      "Generation 918 Best 0.00625 Avg 0.006226513707431235\n",
      "Generation 919 Best 0.00625 Avg 0.006226962087192696\n",
      "Generation 920 Best 0.00625 Avg 0.0062276270682940105\n",
      "Generation 921 Best 0.00625 Avg 0.006227380309011373\n",
      "Generation 922 Best 0.00625 Avg 0.006226281250646949\n",
      "Generation 923 Best 0.00625 Avg 0.00622441864817527\n",
      "Generation 924 Best 0.00625 Avg 0.0062231925024065805\n",
      "Generation 925 Best 0.00625 Avg 0.006230325273773256\n",
      "Generation 926 Best 0.00625 Avg 0.006225921675576895\n",
      "Generation 927 Best 0.00625 Avg 0.006225315196813857\n",
      "Generation 928 Best 0.00625 Avg 0.00622275613776264\n",
      "Generation 929 Best 0.00625 Avg 0.006225384418845765\n",
      "Generation 930 Best 0.00625 Avg 0.006226087289621929\n",
      "Generation 931 Best 0.00625 Avg 0.006224133973381795\n",
      "Generation 932 Best 0.00625 Avg 0.006224858333175226\n",
      "Generation 933 Best 0.00625 Avg 0.0062251252801586825\n",
      "Generation 934 Best 0.00625 Avg 0.006223300726119662\n",
      "Generation 935 Best 0.00625 Avg 0.006223386844051406\n",
      "Generation 936 Best 0.00625 Avg 0.0062272507379797885\n",
      "Generation 937 Best 0.00625 Avg 0.006225403017831367\n",
      "Generation 938 Best 0.00625 Avg 0.00622587502117084\n",
      "Generation 939 Best 0.00625 Avg 0.006221742367728102\n",
      "Generation 940 Best 0.00625 Avg 0.006226754085681466\n",
      "Generation 941 Best 0.00625 Avg 0.006224121184424623\n",
      "Generation 942 Best 0.00625 Avg 0.0062292421863874795\n",
      "Generation 943 Best 0.00625 Avg 0.006224329834004948\n",
      "Generation 944 Best 0.00625 Avg 0.0062281826410632846\n",
      "Generation 945 Best 0.00625 Avg 0.006225981943105306\n",
      "Generation 946 Best 0.00625 Avg 0.006223285431948393\n",
      "Generation 947 Best 0.00625 Avg 0.006224960147281547\n",
      "Generation 948 Best 0.00625 Avg 0.006228019860162686\n",
      "Generation 949 Best 0.00625 Avg 0.0062276235268862844\n",
      "Generation 950 Best 0.00625 Avg 0.006226415408902934\n",
      "Generation 951 Best 0.00625 Avg 0.0062248929957267225\n",
      "Generation 952 Best 0.00625 Avg 0.006227364782640052\n",
      "Generation 953 Best 0.00625 Avg 0.006231519095529878\n",
      "Generation 954 Best 0.00625 Avg 0.006226238291296901\n",
      "Generation 955 Best 0.00625 Avg 0.006223705186378322\n",
      "Generation 956 Best 0.00625 Avg 0.006224416961681275\n",
      "Generation 957 Best 0.00625 Avg 0.00622288604406489\n",
      "Generation 958 Best 0.00625 Avg 0.006229967425323152\n",
      "Generation 959 Best 0.00625 Avg 0.006226472442352541\n",
      "Generation 960 Best 0.00625 Avg 0.0062282049250578534\n",
      "Generation 961 Best 0.00625 Avg 0.006223833662418641\n",
      "Generation 962 Best 0.00625 Avg 0.006224368192479526\n",
      "Generation 963 Best 0.00625 Avg 0.006222413253759703\n",
      "Generation 964 Best 0.00625 Avg 0.0062273132332310716\n",
      "Generation 965 Best 0.00625 Avg 0.006229172621965294\n",
      "Generation 966 Best 0.00625 Avg 0.006222655281786186\n",
      "Generation 967 Best 0.00625 Avg 0.0062261877688175385\n",
      "Generation 968 Best 0.00625 Avg 0.006226444528857381\n",
      "Generation 969 Best 0.00625 Avg 0.006227419418985639\n",
      "Generation 970 Best 0.00625 Avg 0.006225822471040071\n",
      "Generation 971 Best 0.00625 Avg 0.006224576722618653\n",
      "Generation 972 Best 0.00625 Avg 0.006224978693596531\n",
      "Generation 973 Best 0.00625 Avg 0.006227506939414302\n",
      "Generation 974 Best 0.00625 Avg 0.006226730612672949\n",
      "Generation 975 Best 0.00625 Avg 0.006222882604678632\n",
      "Generation 976 Best 0.00625 Avg 0.006226440241999934\n",
      "Generation 977 Best 0.00625 Avg 0.006226361670410152\n",
      "Generation 978 Best 0.00625 Avg 0.006225474701859828\n",
      "Generation 979 Best 0.00625 Avg 0.006228456569662637\n",
      "Generation 980 Best 0.00625 Avg 0.0062236371107367875\n",
      "Generation 981 Best 0.00625 Avg 0.006223398708472739\n",
      "Generation 982 Best 0.00625 Avg 0.006227151155371757\n",
      "Generation 983 Best 0.00625 Avg 0.00622253620484436\n",
      "Generation 984 Best 0.00625 Avg 0.0062273723275086375\n",
      "Generation 985 Best 0.00625 Avg 0.006227985335326155\n",
      "Generation 986 Best 0.00625 Avg 0.006228667459561945\n",
      "Generation 987 Best 0.00625 Avg 0.006227643518093587\n",
      "Generation 988 Best 0.00625 Avg 0.006228348604402598\n",
      "Generation 989 Best 0.00625 Avg 0.0062271488277319915\n",
      "Generation 990 Best 0.00625 Avg 0.006225258591165137\n",
      "Generation 991 Best 0.00625 Avg 0.006224096163446183\n",
      "Generation 992 Best 0.00625 Avg 0.006226355786055202\n",
      "Generation 993 Best 0.00625 Avg 0.006227659163475828\n",
      "Generation 994 Best 0.00625 Avg 0.006226609499252502\n",
      "Generation 995 Best 0.00625 Avg 0.006223363762328367\n",
      "Generation 996 Best 0.00625 Avg 0.00622647345987425\n",
      "Generation 997 Best 0.00625 Avg 0.00622699213734155\n",
      "Generation 998 Best 0.00625 Avg 0.0062252076853799914\n",
      "Generation 999 Best 0.00625 Avg 0.0062263323380223525\n",
      "Order: ['Joshua', 'Narine', 'Daniel', 'David', 'Brian', 'Murat', 'Melanie', 'Michael', 'Wei', 'Dean', 'Lisa', 'Sajid', 'Sarah'] Bytes: 160\n"
     ]
    }
   ],
   "source": [
    "initial_population: List[ListCompression] = [ListCompression.random_instance() for _ in range(1000)]\n",
    "ga: GeneticAlgorithm[ListCompression] = GeneticAlgorithm(initial_population=initial_population, \n",
    "                                                         threshold=1.0, max_generations = 1000, \n",
    "                                                         mutation_chance = 0.2, crossover_chance = 0.7, \n",
    "                                                         selection_type=GeneticAlgorithm.SelectionType.TOURNAMENT)\n",
    "result: ListCompression = ga.run()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Genetic algorithms are not a panacea. In fact, they are not suitable for most problems. For any problem in which a fast deterministic algorithm exists, a genetic algorithm approach does not make sense. Their inherently stochastic nature makes their runtimes unpredictable. To solve this problem, they can be cut off after a certain number of generations. But then it is not clear if a truly optimal solution has been found. \n",
    "\n",
    "Genetic algorithms have been shown to find suboptimal, but pretty good, solutions in short periods of time. The problem is widely applicable to the efficient distribution of goods. For example, dispatchers of FedEx and UPS trucks use software to solve the Traveling Salesman problem every day. Algorithms that help solve the problem can cut costs in a large variety of industries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
